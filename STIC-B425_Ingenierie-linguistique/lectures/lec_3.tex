\lecture{3}{samedi 08 février 2020}
\vspace{-1.2cm}

\section{Systèmes fondés sur les corpus}
\label{sec:corpus}

Apprennent les connaissances à partir des corpus ("data-driven")

\begin{itemize}
    \item Connaissances probabilistes
    \item SMT (statistiques): Restent au niveau de mots. Apprennent des mots + associations entre mots.
    \item NMT (neuronaux): Représentent la sémantique du mot.\\
\end{itemize}


\textbf{Pionniers}\\

Nagao (1984)

Les traducteurs ne ferraient pas une traduction complète de la phrase source. Il propose la base de l'approche statistique. Décomposer la phrase source en segments, puis on traduit les différents segments. À la phase on recompose ces différents segments pour reconstruire la phrase.\\

Isabelle (1992)

Les traductions existantes (corpus) contiennent plus de solutions à des problèmes de traduction que n'importe quelle autre ressource (e.g. des dictionnaires). \\

\textbf{Statistiques VS Linguistiques}

\begin{itemize}
    \item Raisons économiques: moins couteux (outils «open source»)
    \item Pas de ressources linguistiques nécessaires (dictionnaires, grammaires, etc.): seule solution pour les langues peu dotées
    \item Meilleure fluidité que les systèmes linguistiques
    \item Se marie bien avec les mémoires de traduction.\\
\end{itemize}

\textbf{Inconvénients}

\begin{itemize}
    \item Nécessite des corpus représentatifs et assez grands
    \item Moins précis (moins de fidélité). Risque de contresens plus important, même si la phrase semble naturelle.
    \item Difficile à améliorer/modifier de manière transparente
    \item Fonctionne mieux pour des langues proches, sans trop de divergences
    \item Erreurs pas toujours systématiques $\rightarrow$ plus difficile à post-éditer
    \item Nécessite pas mal de ressources informatiques pour les estimer/stocker les modèles\\
\end{itemize}

\subsection{SMT}

\textbf{Historique}

\begin{itemize}
    \item Première technologie envisagée (Weaver)
    \item 1990: premier article à IBM (Brown)
    \item 2006: Google lance le premier système SMT, Google Translate
    \item 2007: Plateforme open-source "Moses" (EuroMatrix) pour développer des systèmes SMT (sous la direction de Koehn)
    \item État de l'art jusqu'en 2016\\
\end{itemize}

\textbf{2 générations de SMT}

\begin{itemize}
    \item TA statistique par mots (word-based machine translation)
    \item TA statistique par segments (phrase-based machine translation)\\
\end{itemize}

\textbf{Objectif}

Trouver pour une phrase Source la phrase Target qui a la plus grande probabilité d'être la traduction de la phrase S.

"The target turn" (Carl): Choisir la bonne solution en Langue Cible, plutôt que d'analyser la Langue Source.\\

\newpage

\textbf{Fonctionnement SMT}

\begin{itemize}
    \item Entrainement
        \begin{itemize}
            \item Corpus Parallèles (bilingues) $\rightarrow$ Analyses statistiques $\rightarrow$ Modèle de traduction: fidélité. Regarde si phrase cible est bonne traduction à partir des mots source.
            \item Corpus monolingue de la langue cible $\rightarrow$ Analyses statistiques $\rightarrow$ Modèle de langage: Regarde si la phrase cible est fluide, "qui se lit bien en langue cible".
            \item On extrait les mots et les associations bilingues/monolingues qui se trouvent dans les corpus, avec leurs fréquences.
            \item On donne ces données aux modèles de traduction/langage.
            \item On décompose le problème de traduction en deux tâches.
        \end{itemize}
    \item Décodage
        \begin{itemize}
            \item Fidélité VS Fluidité
            \item On trouve le meilleur score qui soit un compromis entre ces deux concepts.
            \item Il y a plusieurs modèles statistiques: certains mettent le même poids aux deux modèles, d'autres apporteront plus de poids à l'un d'eux.\\
        \end{itemize}
\end{itemize}

\textbf{Traduction (noisy channel model)}

Problème de décision:

\begin{itemize}
    \item Trouver la meilleure phrase parmi toutes les phrase possibles
    \item $\text{Translation} = Argmax_T P(T) P(S|T)$
    \item P(T) provient du modèle de langue. P(S|T) provient du modèle de traduction. On veut trouver P(T|S). \\
\end{itemize}


\textbf{Modèle de langue}

Objectif: déterminer le score de fluidité de la langue cible P(T).

Modèle de langue N-grammes - séquences de N mots. Il faut trouver un compromis: N-gramme trop petit $\rightarrow$ pas hyper représentatif de la langue; N-gramme trop grand $\rightarrow$ la probabilité de trouver cette chaine dans le corpus est plus petite. On dépasse rarement 6-gramme dans l'état de l'art actuel.

Entrainement: Prend le corpus monolingue, extrait tous les N-grammes et calcule leur probabilité dans le corpus monolingue, c’est-à-dire leur fréquence dans le corpus. \\

Probabilité d'un Bi-gramme: $ \frac{ \text{Freq(1er mot, 2eme mot)}}{\text{Freq(1er mot)}} $ \\

\textbf{Modèle de traduction}

Objectif: déterminer quelle est la traduction la plus fidèle.

Intuitivement: on regarde dans le corpus bilingue dans quelle mesure chaque mot/segment de T est la traduction des mots/segments de la langue S.

Entraînement: part d'un corpus bilingue aligné par mot.

Score de traduction: Nombre de fois où le segment source et cible sont extraits comme bi-segment, divisé par le nombre de fois où le segment source est extrait avec tous les segments.\\

\textbf{Modèle de réordonnancement}

On calcule aussi la probabilité qu’un segment change de place, ce qui permet de traiter des changements d’ordre des mots. Exemple: a good man $\rightarrow$ un homme honnête\\

\textbf{Décodage}

\begin{itemize}
    \item Segmenter la phrases source de toutes les manières possibles.
    \item Chercher les traductions des segments dans la table de traduction.
    \item Réordonner avec le modèle de réordonnancement.
    \item Garder la meilleur solution fluidité(T) * fidélité(S, T).
\end{itemize}


\textbf{Limites}

\begin{itemize}
    \item Gros corpus nécessaires: monolingues et bilingues
    \item Traduisent par segments: Contexte limité à 5-6 mots
    \item Fautes non locales
    \item Ne généralisent pas : si le mot est absent du corpus, il n’est pas traduit\\
\end{itemize}





