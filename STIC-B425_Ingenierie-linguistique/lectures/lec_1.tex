\lecture{1}{mardi 04 février 2020}
\vspace{-1.2cm}

\section{Introduction au cours}

Qu'est-ce que l'ingénierie linguistique? Le nom de ce cours est ancien, aujourd'hui on dirait plutôt
"Introduction au Traitement Automatique des Langues (TAL)". On garde cet ancien nom car il est
intéressant (il mets en évidence qu'il s'agit d'un mix entre sciences "dures" et sciences "sociales"). \\

Il s'agit d'une discipline en constante évolution et hybride. Historiquement, deux disciplines dissociées et
ayant des chercheurs distincts existaient: d'un coté des linguistes s'interrogeant sur ce que l'informatique
pourrait apporter à leur discipline (linguistique informatique), et de l'autre des informaticiens et ingénieurs
curieux d'appliquer leurs modèles mathématiques dans l'étude de la linguistique (traitement automatique des langues).
À présent, les deux disciplines sont communes. \\

\textbf{Applications possibles de la discipline:}\\

\begin{minipage}[t]{0.6\textwidth}
\begin{itemize}
\item Correction orthographique/grammaticale
\item Traduction automatique/assistée
\item Reconnaissance et synthèse vocale
\end{itemize}
\end{minipage}
\begin{minipage}[t]{0.4\textwidth}
\begin{itemize}
\item Extraction d'informations
\item Analyse de sentiments
\item Question answering
\end{itemize}
\end{minipage}

\subsection{Niveaux linguistiques}

\begin{figure}[H]
\centering
\includegraphics[scale=0.25]{lec1img1}
\end{figure}

Dans ce cours on étudie les nombreux niveaux linguistiques existants et les challenges qu'ils apportent au niveau
de l'ingénierie linguistique, car le langage humain est ambigu à tous les niveaux.\\

\begin{itemize}
    \item \textbf{Phonétique / Phonologie}: Hors scope du cours. Reconnaissance de mots depuis un signal audio et
    génération d'un signal audio à partir de mots. Prononciation, réalisation acoustique, etc.
    \item \textbf{Morphologie}: Reconnaissance des variations de forme des mots individuels (pluriel, conjugaison,...).
    \item \textbf{Lexique}: Qu'est-ce qu'un mot? Il faut savoir comment découper une phrase en mots pour la traiter par la suite.
    \item \textbf{Syntaxe}: Reconnaissance de l'ordre des mots et de l'organisation interne d'une phrase structurée.
    \item \textbf{Sémantique}: Reconnaissance du sens intrinsèque des mots (sémantique lexicale) ainsi que de la manière dont
    ils s'influencent mutuellement (sémantique compositionnelle).
    \item \textbf{Pragmatique}: Brièvement discuté lors du cours, mais hors scope du cours. Reconnaissance de l'intention du
    locuteur de la manière appropriée d'y répondre en fonction du contexte.
\end{itemize}

\subsection{Challenges affrontés}

\textbf{Ambigüités possibles:}

\begin{itemize}
    \item \textbf{Ambigüité phonétique}: Homophonie
    \item \textbf{Ambigüité morpho-lexicale}: Homographie
    \item \textbf{Ambigüité syntaxique}
    \item \textbf{Ambigüité sémantique} Hors contexte, certaines phrases peuvent être lues de façons différentes
    \item \textbf{Ambigüité pragmatique}: Ironie, par exemple
    \item \textbf{Ambigüité multilingue} \\
\end{itemize}

\noindent\textbf{Contraintes supplémentaires:}

\begin{itemize}
    \item \textbf{Précision}: Reproduire la compétence linguistique des êtres humains à l'aide de modèles
    formalisant notre compréhension
    \item \textbf{Rappel}: Une bonne couverture de la langue traitée requiert des ressources
    linguistiques (lexiques, grammaires,...) suffisamment fournies
    \item \textbf{Performance}: Un traitement rapide implique de limiter la complexité des modèles linguistiques
\end{itemize}

\subsection{Un peu d'histoire}

\textbf{Hiérarchie de Noam Chomsky (1956)} \\

Classification des grammaires en quatre catégories, de la plus libre à la plus contraignante

\vspace{1cm}

\resizebox{0.9\textwidth}{!}{
    \input{images/lec1_tikz1.tex}
}

\newpage

\textbf{Test de Turing / Imitation Game} \\

Proposition de test d'intelligence artificielle décrit par Alan Turing en 1950. Ce test consiste à mettre un humain en conversation à l'aveugle avec un ordinateur et un autre humain pour évaluer la capacité de cette machine à imiter la conversation humaine. Si le programme réussis à tromper des humains plus de 30\% des fois, on considère le test réussi. \\

De nombreuses objections à ce test ont été suggérées tout comme réfutées depuis des années, certaines par Alan Turing lui-même, mais il reste tout de même un théorème central dans l'étude de l'intelligence artificielle. \\

ELIZA, une simulation de thérapie rogérienne développée en 1966, a été une des premières à tromper des humains mais on peut pas dire qu'il s'agit d'un succès du test de Turing, car les personnes l'utilisant n'avaient aucune raison de suspecter qu'elles ne parlaient pas à un humain, ce qui est l'élément central du test. \\

\subsection{Éclatement de la discipline}

\textbf{Approches linguistiques}

Aussi appelées symboliques ou rule-based. Basées sur la compréhension du langage et
l'intuition humaine. Patterns récurrents + heuristiques simples.
Nécessitent de coder chaque règle à la main : investissement énorme en termes de temps, argent et ressources humaines \\

\textbf{Approches statistiques}

Aussi appelées stochastiques ou probabilistes. Très rapides mais souvent moins précises.

Modèle bayésien naïf : inférence permettant d'estimer la probabilité d'une chaîne de caractères à partir des probabilités de chaînes existantes. \\

\textbf{Approches hybrides}

Combinent la puissance des approches statistiques avec la finesse d'analyse des approches linguistiques.
La plupart des systèmes actuels sont de ce type et incluent donc différentes composantes complémentaires pour atteindre un niveau de pointe. \\

\textbf{Apprentissage automatique}

Plus connu sous le nom de machine learning. Data-driven : nécessite un grand volume de
données pour entraîner les algorithmes.

Utilisation de corpus annotés : Penn Treebank, Brown, Reuters, Europarl...

Supervisé vs non-supervisé. Apprentissage profond (deep learning) et réseaux de neurones.

\subsection{État de l'art}

\textbf{Globalement résolu}

Détéction de spam. Tagging the part-of-speech. "Named entity recognition" (NER).\\

\textbf{En progrès constant}

Analyse de sentiment de texte. Parsing. Traduction automatique. Extraction d'information.\\

\textbf{Toujours très complexe}

Question answering. Paraphrase. Résumé de texte. Dialogue.\\
